{
    "episode_reward_max": 316.0,
    "episode_reward_min": 74.0,
    "episode_reward_mean": 184.35185185185185,
    "episode_len_mean": 100.0,
    "episodes_this_iter": 108,
    "policy_reward_min": {
        "always_defecting": 111.0,
        "vae": -58.0,
        "always_cooperating": 8.0
    },
    "policy_reward_max": {
        "always_defecting": 174.0,
        "vae": 264.0,
        "always_cooperating": 74.0
    },
    "policy_reward_mean": {
        "always_defecting": 143.55,
        "vae": 85.60185185185185,
        "always_cooperating": 42.75
    },
    "custom_metrics": {},
    "hist_stats": {
        "episode_reward": [
            114.0,
            298.0,
            302.0,
            92.0,
            308.0,
            98.0,
            304.0,
            292.0,
            300.0,
            102.0,
            306.0,
            92.0,
            296.0,
            302.0,
            110.0,
            292.0,
            100.0,
            286.0,
            116.0,
            296.0,
            90.0,
            106.0,
            80.0,
            294.0,
            108.0,
            306.0,
            92.0,
            96.0,
            86.0,
            92.0,
            110.0,
            86.0,
            290.0,
            312.0,
            290.0,
            96.0,
            112.0,
            288.0,
            290.0,
            284.0,
            96.0,
            92.0,
            294.0,
            312.0,
            80.0,
            106.0,
            84.0,
            296.0,
            102.0,
            284.0,
            86.0,
            278.0,
            100.0,
            90.0,
            108.0,
            98.0,
            104.0,
            114.0,
            102.0,
            316.0,
            304.0,
            84.0,
            298.0,
            286.0,
            308.0,
            272.0,
            308.0,
            112.0,
            106.0,
            290.0,
            94.0,
            314.0,
            298.0,
            316.0,
            88.0,
            116.0,
            80.0,
            304.0,
            286.0,
            98.0,
            82.0,
            82.0,
            92.0,
            86.0,
            96.0,
            274.0,
            74.0,
            288.0,
            286.0,
            300.0,
            288.0,
            98.0,
            292.0,
            278.0,
            88.0,
            106.0,
            102.0,
            102.0,
            98.0,
            96.0,
            294.0,
            90.0,
            84.0,
            80.0,
            88.0,
            284.0,
            284.0,
            80.0
        ],
        "episode_lengths": [
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100,
            100
        ],
        "policy_always_defecting_reward": [
            171.0,
            138.0,
            147.0,
            153.0,
            138.0,
            165.0,
            150.0,
            174.0,
            135.0,
            159.0,
            120.0,
            162.0,
            138.0,
            144.0,
            129.0,
            138.0,
            165.0,
            129.0,
            144.0,
            168.0,
            144.0,
            138.0,
            120.0,
            159.0,
            126.0,
            153.0,
            129.0,
            150.0,
            135.0,
            162.0,
            147.0,
            156.0,
            171.0,
            153.0,
            126.0,
            168.0,
            159.0,
            141.0,
            132.0,
            174.0,
            120.0,
            147.0,
            123.0,
            123.0,
            138.0,
            129.0,
            144.0,
            111.0,
            147.0,
            132.0,
            159.0,
            153.0,
            153.0,
            147.0,
            144.0,
            135.0,
            126.0,
            120.0,
            132.0,
            120.0
        ],
        "policy_vae_reward": [
            -57.0,
            251.0,
            249.0,
            -46.0,
            246.0,
            -49.0,
            248.0,
            254.0,
            250.0,
            -51.0,
            247.0,
            -46.0,
            252.0,
            249.0,
            -55.0,
            254.0,
            -50.0,
            257.0,
            -58.0,
            252.0,
            -45.0,
            -53.0,
            -40.0,
            253.0,
            -54.0,
            247.0,
            -46.0,
            -48.0,
            -43.0,
            -46.0,
            -55.0,
            -43.0,
            255.0,
            244.0,
            255.0,
            -48.0,
            -56.0,
            256.0,
            255.0,
            258.0,
            -48.0,
            -46.0,
            253.0,
            244.0,
            -40.0,
            -53.0,
            -42.0,
            252.0,
            -51.0,
            258.0,
            -43.0,
            261.0,
            -50.0,
            -45.0,
            -54.0,
            -49.0,
            -52.0,
            -57.0,
            -51.0,
            242.0,
            248.0,
            -42.0,
            251.0,
            257.0,
            246.0,
            264.0,
            246.0,
            -56.0,
            -53.0,
            255.0,
            -47.0,
            243.0,
            251.0,
            242.0,
            -44.0,
            -58.0,
            -40.0,
            248.0,
            257.0,
            -49.0,
            -41.0,
            -41.0,
            -46.0,
            -43.0,
            -48.0,
            263.0,
            -37.0,
            256.0,
            257.0,
            250.0,
            256.0,
            -49.0,
            254.0,
            261.0,
            -44.0,
            -53.0,
            -51.0,
            -51.0,
            -49.0,
            -48.0,
            253.0,
            -45.0,
            -42.0,
            -40.0,
            -44.0,
            258.0,
            258.0,
            -40.0
        ],
        "policy_always_cooperating_reward": [
            47.0,
            53.0,
            62.0,
            56.0,
            38.0,
            50.0,
            59.0,
            44.0,
            53.0,
            38.0,
            29.0,
            44.0,
            41.0,
            59.0,
            35.0,
            68.0,
            35.0,
            32.0,
            35.0,
            26.0,
            41.0,
            68.0,
            44.0,
            26.0,
            17.0,
            74.0,
            56.0,
            47.0,
            29.0,
            62.0,
            8.0,
            62.0,
            35.0,
            71.0,
            47.0,
            74.0,
            56.0,
            29.0,
            11.0,
            32.0,
            29.0,
            50.0,
            32.0,
            38.0,
            17.0,
            41.0,
            26.0,
            26.0
        ]
    },
    "sampler_perf": {
        "mean_env_wait_ms": 0.01634540127021608,
        "mean_processing_ms": 0.100448073733407,
        "mean_inference_ms": 1.2707071069478326
    },
    "off_policy_estimator": {},
    "info": {
        "num_steps_trained": 10800,
        "num_steps_sampled": 10800,
        "sample_time_ms": 153.432,
        "grad_time_ms": 7.177,
        "update_time_ms": 1.463,
        "opt_peak_throughput": 27867.278,
        "sample_peak_throughput": 1303.507,
        "opt_samples": 200.0,
        "learner": {
            "always_defecting": {},
            "vae": {}
        }
    },
    "optimizer_steps_this_iter": 54,
    "timesteps_this_iter": 10800,
    "done": false,
    "timesteps_total": 10800,
    "episodes_total": 108,
    "training_iteration": 1,
    "experiment_id": "84fcf624992e4b24a61bfc54ea6beb7f",
    "date": "2020-05-22_19-17-42",
    "timestamp": 1590175062,
    "time_this_iter_s": 10.146957159042358,
    "time_total_s": 10.146957159042358,
    "pid": 5655,
    "hostname": "b0e6f9fe1470",
    "node_ip": "172.17.0.2",
    "config": {
        "num_workers": 2,
        "num_envs_per_worker": 1,
        "rollout_fragment_length": 20,
        "sample_batch_size": -1,
        "batch_mode": "truncate_episodes",
        "num_gpus": 0,
        "train_batch_size": 200,
        "model": {
            "conv_filters": null,
            "conv_activation": "relu",
            "fcnet_activation": "tanh",
            "fcnet_hiddens": [
                256,
                256
            ],
            "free_log_std": false,
            "no_final_linear": false,
            "vf_share_layers": true,
            "use_lstm": false,
            "max_seq_len": 20,
            "lstm_cell_size": 256,
            "lstm_use_prev_action_reward": false,
            "state_shape": null,
            "framestack": true,
            "dim": 84,
            "grayscale": false,
            "zero_mean": true,
            "custom_model": null,
            "custom_action_dist": null,
            "custom_options": {},
            "custom_preprocessor": null
        },
        "optimizer": {},
        "gamma": 0.99,
        "horizon": null,
        "soft_horizon": false,
        "no_done_at_end": false,
        "env_config": {
            "max_steps": 100
        },
        "env": "IteratedPrisonersDilemma",
        "normalize_actions": false,
        "clip_rewards": null,
        "clip_actions": true,
        "preprocessor_pref": "deepmind",
        "lr": 0.0001,
        "monitor": false,
        "log_level": "WARN",
        "callbacks": "<not serializable>",
        "ignore_worker_failures": false,
        "log_sys_usage": true,
        "use_pytorch": false,
        "eager": true,
        "eager_tracing": false,
        "no_eager_on_workers": false,
        "explore": true,
        "exploration_config": {
            "type": "StochasticSampling"
        },
        "evaluation_interval": null,
        "evaluation_num_episodes": 10,
        "in_evaluation": false,
        "evaluation_config": {},
        "evaluation_num_workers": 0,
        "custom_eval_function": null,
        "use_exec_api": false,
        "sample_async": false,
        "observation_filter": "NoFilter",
        "synchronize_filters": true,
        "tf_session_args": {
            "intra_op_parallelism_threads": 2,
            "inter_op_parallelism_threads": 2,
            "gpu_options": {
                "allow_growth": true
            },
            "log_device_placement": false,
            "device_count": {
                "CPU": 1
            },
            "allow_soft_placement": true
        },
        "local_tf_session_args": {
            "intra_op_parallelism_threads": 8,
            "inter_op_parallelism_threads": 8
        },
        "compress_observations": false,
        "collect_metrics_timeout": 180,
        "metrics_smoothing_episodes": 100,
        "remote_worker_envs": false,
        "remote_env_batch_wait_ms": 0,
        "min_iter_time_s": 10,
        "timesteps_per_iteration": 0,
        "seed": null,
        "extra_python_environs_for_driver": {},
        "extra_python_environs_for_worker": {},
        "num_cpus_per_worker": 1,
        "num_gpus_per_worker": 0,
        "custom_resources_per_worker": {},
        "num_cpus_for_driver": 1,
        "memory": 0,
        "object_store_memory": 0,
        "memory_per_worker": 0,
        "object_store_memory_per_worker": 0,
        "input": "sampler",
        "input_evaluation": [
            "is",
            "wis"
        ],
        "postprocess_inputs": false,
        "shuffle_buffer_size": 0,
        "output": null,
        "output_compress_columns": [
            "obs",
            "new_obs"
        ],
        "output_max_file_size": 67108864,
        "multiagent": {
            "policies": {
                "always_defecting": [
                    "<not serializable>",
                    "<not serializable>",
                    "<not serializable>",
                    {}
                ],
                "always_cooperating": [
                    "<not serializable>",
                    "<not serializable>",
                    "<not serializable>",
                    {}
                ],
                "vae": [
                    "<not serializable>",
                    "<not serializable>",
                    "<not serializable>",
                    {}
                ]
            },
            "policy_mapping_fn": "<not serializable>",
            "policies_to_train": []
        },
        "use_critic": true,
        "use_gae": true,
        "lambda": 1.0,
        "grad_clip": 40.0,
        "lr_schedule": null,
        "vf_loss_coeff": 0.5,
        "entropy_coeff": 0.01,
        "microbatch_size": null
    },
    "time_since_restore": 10.146957159042358,
    "timesteps_since_restore": 10800,
    "iterations_since_restore": 1,
    "perf": {
        "cpu_util_percent": 66.52666666666666,
        "ram_util_percent": 40.86
    },
    "num_healthy_workers": 2
}